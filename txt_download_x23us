import os
import re
from urllib import parse

import httpx
from bs4 import BeautifulSoup

import agent

catalogue_url = "https://www.x23us.us/126_126213/"
headers = {"referer": catalogue_url, "user-agent": agent.get_user_agents()}


def remove_title(title: str):
    path = os.path.join("books", f"{title}.txt")
    if os.path.exists(path):
        os.remove(path)


def chineseNumber2Int(strNum: str):
    result = 0
    temp = 1  # 存放一个单位的数字如：十万
    count = 0  # 判断是否有chArr
    cnArr = ["一", "二", "三", "四", "五", "六", "七", "八", "九"]
    chArr = ["十", "百", "千", "万", "亿"]
    for i in range(len(strNum)):
        b = True
        c = strNum[i]
        for j in range(len(cnArr)):
            if c == cnArr[j]:
                if count != 0:
                    result += temp
                    count = 0
                temp = j + 1
                b = False
                break
        if b:
            for j in range(len(chArr)):
                if c == chArr[j]:
                    if j == 0:
                        temp *= 10
                    elif j == 1:
                        temp *= 100
                    elif j == 2:
                        temp *= 1000
                    elif j == 3:
                        temp *= 10000
                    elif j == 4:
                        temp *= 100000000
                count += 1
        if i == len(strNum) - 1:
            result += temp
    return result


def get_catalogue_url_list(url):
    resp = httpx.get(url, headers=headers, timeout=None)
    resp.encoding = "utf-8"
    catalogue_page = resp.text
    catalogue_soup = BeautifulSoup(catalogue_page, "lxml")
    now_title = catalogue_soup.h1.string
    zhangjie_box = catalogue_soup.find("div", id="list")
    zhangjie_list = zhangjie_box.find_all("dd")
    for i in range(len(zhangjie_list)):
        relative_link = zhangjie_list[i].a["href"]
        zhangjie_list[i] = parse.urljoin(url, relative_link)
    return zhangjie_list, str(now_title)


def get_novel_content(client, url, novel_title):
    resp = client.get(url, timeout=None)
    resp.encoding = "utf-8"
    novel_page = resp.text
    novel_soup = BeautifulSoup(novel_page, "lxml")
    if resp.status_code != 200:
        print("目标网址访问失败：")
        raise httpx.ConnectError("\n".join(novel_soup.stripped_strings))
    zhangjie_title = str(novel_soup.h1.string).strip()
    zhangjie_title_correct = re.compile("囚星天狱")
    if re.match(zhangjie_title_correct, zhangjie_title):
        zhangjie_title = zhangjie_title[5:]
    num_pattern = re.compile(r"第(.+?)[章张]")
    title_match = re.match(num_pattern, zhangjie_title)
    if title_match:
        raw_num = title_match.group(1)
        if not raw_num.isdecimal():
            title_num = chineseNumber2Int(raw_num)
            zhangjie_num = f"第{str(title_num)}章"
            zhangjie_title = zhangjie_title.replace(title_match.group(0), zhangjie_num)
    novel_text = novel_soup.find(id="content").get_text()
    txt_write(novel_title, zhangjie_title, novel_text)


def txt_write(novel_title, zhangjie_title, novel_text):
    path = os.path.join("books", f"{novel_title}.txt")
    with open(path, "a", encoding="utf-8") as f:
        f.write(f"{zhangjie_title}\n")
        f.write(novel_text)
    print(zhangjie_title)


def main():
    url_list, novel_title = get_catalogue_url_list(catalogue_url)
    remove_title(novel_title)
    with httpx.Client(headers=headers) as client:
        for novel_url in url_list:
            get_novel_content(client, novel_url, novel_title)


if __name__ == "__main__":
    main()
